{
  "title": "Things are changing very fast here.",
  "description": "Some thoughts on recent technological developments",
  "date": "2023-09-28T00:00:00.000Z",
  "published": true,
  "image": "/images/blog/20230928-blog-2-1.jpg",
  "authors": [
    "hongzhi"
  ],
  "body": {
    "raw": "\nA month ago, on one occasion, a senior engineer at Google was invited to speak to us. When asked what it was like for her to work at Google, she said:\n\n1 个月前，在某个场合中，一位谷歌的高级工程师被邀请来给我们讲话，当被问到她在谷歌工作是什么样时，她说：\n\n> These days, things are changing very fast here.\n\n> 这些天，事情正在很快地改变着。\n\nConsidering that the industry is rapidly being affected by AI, since the popularity of chatGPT, Midjourney, and Stable Diffusion, basically all products are currently or will be updated in the future and are related to AI. So I also want to sort out and look forward to future development trends.\n\n考虑到行业正在迅速地被 AI 所影响着自从 chatGPT，Midjourney，Stable Diffusion 的火爆，基本所有的产品目前或者下一步更新都和 AI 有关。所以我也想梳理和展望一下未来的发展趋势。\n\n---\n\nHalf a year ago, people were still teasing how distorted the hands of characters in AI drawings were. However, today, we can see some images that are comparable to photography. Perhaps one of the differences is that: AI image is too smooth and perfect.\n\n半年前，人们还在调侃 AI 画的人物手有多扭曲。 然而今天，我们可以看到一些堪比摄影的图像, 也许差异之一是：AI 图像过于流畅和完美。\n\n---\n\n### In terms of images (图像处理方面)\n\nIt is now possible to embed text into natural images [here](https://x.com/daniel_eckler/status/1705202342159884742?s=20) and [there](https://x.com/fabianstelzer/status/1704146823877730683?s=20) , which is perfect for posters or advertisement. This may takes a long time for human designers to design and create. We can even make some short animations to make the pictures move ([check here](https://x.com/DiffusionPics/status/1706391310561841206?s=20) and [here](https://x.com/mhgenerate/status/1704271148328841405?s=20)). Such an achievement is not difficult to expect before: a video is made of pictures frame by frame. Now AI can generate pictures, how far are we from videos and animations?\n\n现在我们可以将文本嵌入到自然图像中([此处](https://x.com/daniel_eckler/status/1705202342159884742?s=20)和[此处](https://x.com/fabianstelzer/status/1704146823877730683?s=20))，非常适合海报或广告。 这可能需要人类设计师花费很长的时间来设计和创造。我们甚至可以制作一些简短的动画(查看[此处](https://x.com/DiffusionPics/status/1706391310561841206?s=20)和[此处](https://x.com/mhgenerate/status/1704271148328841405?s=20))。这样的成就并不难预料到：视频是由一帧一帧的图片组成的。现在 AI 可以生成图片了，我们离视频、动画还有多远？\n\n---\n\n### In terms of speech (语音方面)\n\ntoday we can already see that AI can imitate a person's tone of voice. In terms of computer vision, we can now easily make a person's mouth make various mouth shapes. So with the combination of these technologies, not surprisingly, we have such a tool: a person speaks in a video in English, and then through AI, the content of his speech, the characteristics of his voice, and even the shape of his mouth have become speaking another language. Of course, if we want to truly understand and integrate into a place and culture, we will still learn the language, but imagine how much less inconvenient this will be for a monolingual person.\n\n今天我们已经可以看到人工智能可以模仿人的语气。在计算机视觉方面，我们现在可以轻松地让一个人的嘴巴做出各种嘴型。那么有了这些技术的结合，不出意外，我们就有了这样一个工具：一个人用英语在视频中说话，然后通过 AI，得到他说话的内容，他声音的特征，甚至他嘴的形状 已经变成说另一种语言了。 当然，如果我们想真正理解并融入一个地方和文化，我们仍然会学习语言，但想象一下这对于只会一种语言的人来说会减少多少不便。\n\n---\n\n### In terms of hardware (硬件方面)\n\nwe have seen IT giants entering space computing and the metaverse. Yesterday I saw Meta Glasses, which can help us immediately determine how long it takes the barbecue to finish, whether there is any foul play during sports, and landmarks information. Relevantly, chatGPT’s latest image input feature can guide us on how to repair bicycles. Think about what this will look like if it is placed on glasses.\n\n我们已经看到 IT 巨头进入空间计算和元宇宙的布局。昨天我看到了 Meta Glasses，它可以帮助我们立即判断面前的烤肉要烤多久，运动过程中是否有犯规行为，以及地标信息。 与此相关的是，chatGPT 最新的图像输入功能可以指导我们如何修理自行车。 想象一下如果把它戴在眼镜上会是什么样子。\n\n---\n\n### So we can imagine a future like this (未来展望) :\n\n1. In the future, everyone can make short movies and animations. It is as easy as writing a blog or post. You can choose the characters (even yourself) and their voice characteristics. (A 2-hour movie or TV series may be as difficult as writing a book, but of course it’s difficult from another perspective). No wonder Hollywood wants to obtain the rights to use the actors’ AI portraits, haha.\n\n未来人人都可以制作短片、动画，就像写博客或帖子一样简单。你可以选择角色（甚至您自己）及其声音特征。（一部 2 小时的电影或电视剧可能和写一本书一样困难，但是这是另一个角度的困难）。难怪好莱坞要获得演员 AI 肖像的使用权，哈哈。\n\n---\n\n2. Everyone has a customized Jarvis. It is no longer sci-fi. Put it in glasses, it can teach you how to draw on the white paper in front of you and display the music sheet in front of your face when you play instrument, telling you what to play next when you practice the piano, or teaching you how to cook step by step.\n\n每个人都有一个定制的贾维斯。这不再是科幻小说。把它放在眼镜里，它可以教你如何在你面前的白纸上画画，并在你演奏乐器时将乐谱显示在你面前，在你练习钢琴时告诉你接下来要演奏什么，或者教你如何一步一步做饭。\n\n---\n\n3. No customer service. Although I still hate the AI's voice and stupidity when I'm on the phone now, I've been asking chatGPT a lot of things. If product descriptions and so on are used for training by large models in the future, then we can solve any product usage problems locally through glasses or mobile phones.\n\n没有客服。虽然我现在打电话时仍然讨厌 AI 的声音和愚蠢，但我已经向 chatGPT 询问了很多事情。如果未来大模型使用产品使用说明等进行训练，那么我们可以通过眼镜或手机在本地解决任何产品使用问题。\n\n---\n\n4. Other scenarios. You don’t want to read several pages of a contract word for word, so you take a picture of it and give it to the AI (distrustful though), and it can help you figure out where there are hidden things agains you or unreasonable aspects. Or you are parking on the side of the road, and the complicated instructions make you confused, but [AI can directly tell you whether you can park and how long you can park.](https://x.com/petergyang/status/1707169696049668472?s=20)\n\n其他场景。你不想逐字逐句地阅读几页合同，所以你把它拍下来交给人工智能（尽管存在不信任问题），它可以帮助你找出哪里有对你不利或不合理的地方。或者你在路边停车，复杂的指令让你一头雾水，但[AI 可以直接告诉你是否可以停车以及可以停车多长时间。](https://x.com/petergang/status/1707169696049668472?s=20)\n\n---\n\nThe current large models are based on the huge amount of data training, and winning by quantity is never the optimal solution. That’s why Sam Altman said,\n\n目前的大型模型都是基于海量数据训练，而以量取胜从来都不是最优方案。这就是为什么 Sam Altman 说，\n\n> we’re at the end of the era where it’s gonna be these giant models, and we’ll make them better in other ways.\n\n> 我们正处于这些巨型模型时代的末期，我们将通过其他方式让它们变得更好。\n\n---\n\n### Ending (结语)\n\nI really want to pick up the knowledge of machine learning and deep learning again when I have free time, and keep up with the current trends, but I always feel that I am unable to do so. Because whether it is papers or products, they are developing too fast.\n\n我很想有空的时候重新拾起机器学习和深度学习的知识，跟上当前的潮流，但总觉得力不从心。 因为无论是论文还是产品，它们发展得太快了。\n\nThe picture at the beginning is of a steam engine. Now that steam engines are available, would the industrial revolution be far in the future? We truly live in an age of wonder.\n\n开头的图片是蒸汽机。既然蒸汽机已经问世，工业革命还会遥远吗？我们确实生活在一个充满神奇的时代。\n",
    "code": "var Component=(()=>{var st=Object.create;var S=Object.defineProperty;var lt=Object.getOwnPropertyDescriptor;var ut=Object.getOwnPropertyNames;var dt=Object.getPrototypeOf,bt=Object.prototype.hasOwnProperty;var q=(u,t)=>()=>(t||u((t={exports:{}}).exports,t),t.exports),mt=(u,t)=>{for(var p in t)S(u,p,{get:t[p],enumerable:!0})},ve=(u,t,p,N)=>{if(t&&typeof t==\"object\"||typeof t==\"function\")for(let y of ut(t))!bt.call(u,y)&&y!==p&&S(u,y,{get:()=>t[y],enumerable:!(N=lt(t,y))||N.enumerable});return u};var ft=(u,t,p)=>(p=u!=null?st(dt(u)):{},ve(t||!u||!u.__esModule?S(p,\"default\",{value:u,enumerable:!0}):p,u)),ht=u=>ve(S({},\"__esModule\",{value:!0}),u);var xe=q((vt,we)=>{we.exports=React});var De=q(z=>{\"use strict\";(function(){\"use strict\";var u=xe(),t=Symbol.for(\"react.element\"),p=Symbol.for(\"react.portal\"),N=Symbol.for(\"react.fragment\"),y=Symbol.for(\"react.strict_mode\"),B=Symbol.for(\"react.profiler\"),X=Symbol.for(\"react.provider\"),K=Symbol.for(\"react.context\"),k=Symbol.for(\"react.forward_ref\"),C=Symbol.for(\"react.suspense\"),O=Symbol.for(\"react.suspense_list\"),U=Symbol.for(\"react.memo\"),A=Symbol.for(\"react.lazy\"),Ue=Symbol.for(\"react.offscreen\"),J=Symbol.iterator,Re=\"@@iterator\";function Te(e){if(e===null||typeof e!=\"object\")return null;var n=J&&e[J]||e[Re];return typeof n==\"function\"?n:null}var w=u.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function m(e){{for(var n=arguments.length,i=new Array(n>1?n-1:0),o=1;o<n;o++)i[o-1]=arguments[o];He(\"error\",e,i)}}function He(e,n,i){{var o=w.ReactDebugCurrentFrame,s=o.getStackAddendum();s!==\"\"&&(n+=\"%s\",i=i.concat([s]));var l=i.map(function(c){return String(c)});l.unshift(\"Warning: \"+n),Function.prototype.apply.call(console[e],console,l)}}var Pe=!1,Ie=!1,Se=!1,Ce=!1,Oe=!1,Z;Z=Symbol.for(\"react.module.reference\");function Ae(e){return!!(typeof e==\"string\"||typeof e==\"function\"||e===N||e===B||Oe||e===y||e===C||e===O||Ce||e===Ue||Pe||Ie||Se||typeof e==\"object\"&&e!==null&&(e.$$typeof===A||e.$$typeof===U||e.$$typeof===X||e.$$typeof===K||e.$$typeof===k||e.$$typeof===Z||e.getModuleId!==void 0))}function je(e,n,i){var o=e.displayName;if(o)return o;var s=n.displayName||n.name||\"\";return s!==\"\"?i+\"(\"+s+\")\":i}function Q(e){return e.displayName||\"Context\"}function _(e){if(e==null)return null;if(typeof e.tag==\"number\"&&m(\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\"),typeof e==\"function\")return e.displayName||e.name||null;if(typeof e==\"string\")return e;switch(e){case N:return\"Fragment\";case p:return\"Portal\";case B:return\"Profiler\";case y:return\"StrictMode\";case C:return\"Suspense\";case O:return\"SuspenseList\"}if(typeof e==\"object\")switch(e.$$typeof){case K:var n=e;return Q(n)+\".Consumer\";case X:var i=e;return Q(i._context)+\".Provider\";case k:return je(e,e.render,\"ForwardRef\");case U:var o=e.displayName||null;return o!==null?o:_(e.type)||\"Memo\";case A:{var s=e,l=s._payload,c=s._init;try{return _(c(l))}catch{return null}}}return null}var v=Object.assign,E=0,ee,te,ne,re,ie,oe,ae;function ce(){}ce.__reactDisabledLog=!0;function Fe(){{if(E===0){ee=console.log,te=console.info,ne=console.warn,re=console.error,ie=console.group,oe=console.groupCollapsed,ae=console.groupEnd;var e={configurable:!0,enumerable:!0,value:ce,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}E++}}function Ye(){{if(E--,E===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:v({},e,{value:ee}),info:v({},e,{value:te}),warn:v({},e,{value:ne}),error:v({},e,{value:re}),group:v({},e,{value:ie}),groupCollapsed:v({},e,{value:oe}),groupEnd:v({},e,{value:ae})})}E<0&&m(\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\")}}var j=w.ReactCurrentDispatcher,F;function R(e,n,i){{if(F===void 0)try{throw Error()}catch(s){var o=s.stack.trim().match(/\\n( *(at )?)/);F=o&&o[1]||\"\"}return`\n`+F+e}}var Y=!1,T;{var We=typeof WeakMap==\"function\"?WeakMap:Map;T=new We}function se(e,n){if(!e||Y)return\"\";{var i=T.get(e);if(i!==void 0)return i}var o;Y=!0;var s=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var l;l=j.current,j.current=null,Fe();try{if(n){var c=function(){throw Error()};if(Object.defineProperty(c.prototype,\"props\",{set:function(){throw Error()}}),typeof Reflect==\"object\"&&Reflect.construct){try{Reflect.construct(c,[])}catch(g){o=g}Reflect.construct(e,[],c)}else{try{c.call()}catch(g){o=g}e.call(c.prototype)}}else{try{throw Error()}catch(g){o=g}e()}}catch(g){if(g&&o&&typeof g.stack==\"string\"){for(var a=g.stack.split(`\n`),f=o.stack.split(`\n`),d=a.length-1,b=f.length-1;d>=1&&b>=0&&a[d]!==f[b];)b--;for(;d>=1&&b>=0;d--,b--)if(a[d]!==f[b]){if(d!==1||b!==1)do if(d--,b--,b<0||a[d]!==f[b]){var h=`\n`+a[d].replace(\" at new \",\" at \");return e.displayName&&h.includes(\"<anonymous>\")&&(h=h.replace(\"<anonymous>\",e.displayName)),typeof e==\"function\"&&T.set(e,h),h}while(d>=1&&b>=0);break}}}finally{Y=!1,j.current=l,Ye(),Error.prepareStackTrace=s}var D=e?e.displayName||e.name:\"\",Ne=D?R(D):\"\";return typeof e==\"function\"&&T.set(e,Ne),Ne}function Me(e,n,i){return se(e,!1)}function $e(e){var n=e.prototype;return!!(n&&n.isReactComponent)}function H(e,n,i){if(e==null)return\"\";if(typeof e==\"function\")return se(e,$e(e));if(typeof e==\"string\")return R(e);switch(e){case C:return R(\"Suspense\");case O:return R(\"SuspenseList\")}if(typeof e==\"object\")switch(e.$$typeof){case k:return Me(e.render);case U:return H(e.type,n,i);case A:{var o=e,s=o._payload,l=o._init;try{return H(l(s),n,i)}catch{}}}return\"\"}var P=Object.prototype.hasOwnProperty,le={},ue=w.ReactDebugCurrentFrame;function I(e){if(e){var n=e._owner,i=H(e.type,e._source,n?n.type:null);ue.setExtraStackFrame(i)}else ue.setExtraStackFrame(null)}function Le(e,n,i,o,s){{var l=Function.call.bind(P);for(var c in e)if(l(e,c)){var a=void 0;try{if(typeof e[c]!=\"function\"){var f=Error((o||\"React class\")+\": \"+i+\" type `\"+c+\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\"+typeof e[c]+\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\");throw f.name=\"Invariant Violation\",f}a=e[c](n,c,o,i,null,\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\")}catch(d){a=d}a&&!(a instanceof Error)&&(I(s),m(\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\",o||\"React class\",i,c,typeof a),I(null)),a instanceof Error&&!(a.message in le)&&(le[a.message]=!0,I(s),m(\"Failed %s type: %s\",i,a.message),I(null))}}}var Ve=Array.isArray;function W(e){return Ve(e)}function qe(e){{var n=typeof Symbol==\"function\"&&Symbol.toStringTag,i=n&&e[Symbol.toStringTag]||e.constructor.name||\"Object\";return i}}function ze(e){try{return de(e),!1}catch{return!0}}function de(e){return\"\"+e}function be(e){if(ze(e))return m(\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\",qe(e)),de(e)}var G=w.ReactCurrentOwner,Be={key:!0,ref:!0,__self:!0,__source:!0},me,fe,M;M={};function Xe(e){if(P.call(e,\"ref\")){var n=Object.getOwnPropertyDescriptor(e,\"ref\").get;if(n&&n.isReactWarning)return!1}return e.ref!==void 0}function Ke(e){if(P.call(e,\"key\")){var n=Object.getOwnPropertyDescriptor(e,\"key\").get;if(n&&n.isReactWarning)return!1}return e.key!==void 0}function Je(e,n){if(typeof e.ref==\"string\"&&G.current&&n&&G.current.stateNode!==n){var i=_(G.current.type);M[i]||(m('Component \"%s\" contains the string ref \"%s\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref',_(G.current.type),e.ref),M[i]=!0)}}function Ze(e,n){{var i=function(){me||(me=!0,m(\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",n))};i.isReactWarning=!0,Object.defineProperty(e,\"key\",{get:i,configurable:!0})}}function Qe(e,n){{var i=function(){fe||(fe=!0,m(\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",n))};i.isReactWarning=!0,Object.defineProperty(e,\"ref\",{get:i,configurable:!0})}}var et=function(e,n,i,o,s,l,c){var a={$$typeof:t,type:e,key:n,ref:i,props:c,_owner:l};return a._store={},Object.defineProperty(a._store,\"validated\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(a,\"_self\",{configurable:!1,enumerable:!1,writable:!1,value:o}),Object.defineProperty(a,\"_source\",{configurable:!1,enumerable:!1,writable:!1,value:s}),Object.freeze&&(Object.freeze(a.props),Object.freeze(a)),a};function tt(e,n,i,o,s){{var l,c={},a=null,f=null;i!==void 0&&(be(i),a=\"\"+i),Ke(n)&&(be(n.key),a=\"\"+n.key),Xe(n)&&(f=n.ref,Je(n,s));for(l in n)P.call(n,l)&&!Be.hasOwnProperty(l)&&(c[l]=n[l]);if(e&&e.defaultProps){var d=e.defaultProps;for(l in d)c[l]===void 0&&(c[l]=d[l])}if(a||f){var b=typeof e==\"function\"?e.displayName||e.name||\"Unknown\":e;a&&Ze(c,b),f&&Qe(c,b)}return et(e,a,f,s,o,G.current,c)}}var $=w.ReactCurrentOwner,he=w.ReactDebugCurrentFrame;function x(e){if(e){var n=e._owner,i=H(e.type,e._source,n?n.type:null);he.setExtraStackFrame(i)}else he.setExtraStackFrame(null)}var L;L=!1;function V(e){return typeof e==\"object\"&&e!==null&&e.$$typeof===t}function pe(){{if($.current){var e=_($.current.type);if(e)return`\n\nCheck the render method of \\``+e+\"`.\"}return\"\"}}function nt(e){{if(e!==void 0){var n=e.fileName.replace(/^.*[\\\\\\/]/,\"\"),i=e.lineNumber;return`\n\nCheck your code at `+n+\":\"+i+\".\"}return\"\"}}var _e={};function rt(e){{var n=pe();if(!n){var i=typeof e==\"string\"?e:e.displayName||e.name;i&&(n=`\n\nCheck the top-level render call using <`+i+\">.\")}return n}}function ge(e,n){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var i=rt(n);if(_e[i])return;_e[i]=!0;var o=\"\";e&&e._owner&&e._owner!==$.current&&(o=\" It was passed a child from \"+_(e._owner.type)+\".\"),x(e),m('Each child in a list should have a unique \"key\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.',i,o),x(null)}}function ye(e,n){{if(typeof e!=\"object\")return;if(W(e))for(var i=0;i<e.length;i++){var o=e[i];V(o)&&ge(o,n)}else if(V(e))e._store&&(e._store.validated=!0);else if(e){var s=Te(e);if(typeof s==\"function\"&&s!==e.entries)for(var l=s.call(e),c;!(c=l.next()).done;)V(c.value)&&ge(c.value,n)}}}function it(e){{var n=e.type;if(n==null||typeof n==\"string\")return;var i;if(typeof n==\"function\")i=n.propTypes;else if(typeof n==\"object\"&&(n.$$typeof===k||n.$$typeof===U))i=n.propTypes;else return;if(i){var o=_(n);Le(i,e.props,\"prop\",o,e)}else if(n.PropTypes!==void 0&&!L){L=!0;var s=_(n);m(\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\",s||\"Unknown\")}typeof n.getDefaultProps==\"function\"&&!n.getDefaultProps.isReactClassApproved&&m(\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\")}}function ot(e){{for(var n=Object.keys(e.props),i=0;i<n.length;i++){var o=n[i];if(o!==\"children\"&&o!==\"key\"){x(e),m(\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\",o),x(null);break}}e.ref!==null&&(x(e),m(\"Invalid attribute `ref` supplied to `React.Fragment`.\"),x(null))}}function at(e,n,i,o,s,l){{var c=Ae(e);if(!c){var a=\"\";(e===void 0||typeof e==\"object\"&&e!==null&&Object.keys(e).length===0)&&(a+=\" You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.\");var f=nt(s);f?a+=f:a+=pe();var d;e===null?d=\"null\":W(e)?d=\"array\":e!==void 0&&e.$$typeof===t?(d=\"<\"+(_(e.type)||\"Unknown\")+\" />\",a=\" Did you accidentally export a JSX literal instead of a component?\"):d=typeof e,m(\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\",d,a)}var b=tt(e,n,i,s,l);if(b==null)return b;if(c){var h=n.children;if(h!==void 0)if(o)if(W(h)){for(var D=0;D<h.length;D++)ye(h[D],e);Object.freeze&&Object.freeze(h)}else m(\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\");else ye(h,e)}return e===N?ot(b):it(b),b}}var ct=at;z.Fragment=N,z.jsxDEV=ct})()});var Ge=q((xt,Ee)=>{\"use strict\";Ee.exports=De()});var yt={};mt(yt,{default:()=>gt,frontmatter:()=>pt});var r=ft(Ge()),pt={title:\"Things are changing very fast here.\",description:\"Some thoughts on recent technological developments\",image:\"/images/blog/20230928-blog-2-1.jpg\",date:\"2023-09-28\",authors:[\"hongzhi\"]};function ke(u){let t=Object.assign({p:\"p\",blockquote:\"blockquote\",hr:\"hr\",h3:\"h3\",a:\"a\",span:\"span\",ol:\"ol\",li:\"li\"},u.components);return(0,r.jsxDEV)(r.Fragment,{children:[(0,r.jsxDEV)(t.p,{children:\"A month ago, on one occasion, a senior engineer at Google was invited to speak to us. When asked what it was like for her to work at Google, she said:\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:10,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"1 \\u4E2A\\u6708\\u524D\\uFF0C\\u5728\\u67D0\\u4E2A\\u573A\\u5408\\u4E2D\\uFF0C\\u4E00\\u4F4D\\u8C37\\u6B4C\\u7684\\u9AD8\\u7EA7\\u5DE5\\u7A0B\\u5E08\\u88AB\\u9080\\u8BF7\\u6765\\u7ED9\\u6211\\u4EEC\\u8BB2\\u8BDD\\uFF0C\\u5F53\\u88AB\\u95EE\\u5230\\u5979\\u5728\\u8C37\\u6B4C\\u5DE5\\u4F5C\\u662F\\u4EC0\\u4E48\\u6837\\u65F6\\uFF0C\\u5979\\u8BF4\\uFF1A\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:12,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.blockquote,{children:[`\n`,(0,r.jsxDEV)(t.p,{children:\"These days, things are changing very fast here.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:14,columnNumber:3},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:14,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.blockquote,{children:[`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u8FD9\\u4E9B\\u5929\\uFF0C\\u4E8B\\u60C5\\u6B63\\u5728\\u5F88\\u5FEB\\u5730\\u6539\\u53D8\\u7740\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:16,columnNumber:3},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:16,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"Considering that the industry is rapidly being affected by AI, since the popularity of chatGPT, Midjourney, and Stable Diffusion, basically all products are currently or will be updated in the future and are related to AI. So I also want to sort out and look forward to future development trends.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:18,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u8003\\u8651\\u5230\\u884C\\u4E1A\\u6B63\\u5728\\u8FC5\\u901F\\u5730\\u88AB AI \\u6240\\u5F71\\u54CD\\u7740\\u81EA\\u4ECE chatGPT\\uFF0CMidjourney\\uFF0CStable Diffusion \\u7684\\u706B\\u7206\\uFF0C\\u57FA\\u672C\\u6240\\u6709\\u7684\\u4EA7\\u54C1\\u76EE\\u524D\\u6216\\u8005\\u4E0B\\u4E00\\u6B65\\u66F4\\u65B0\\u90FD\\u548C AI \\u6709\\u5173\\u3002\\u6240\\u4EE5\\u6211\\u4E5F\\u60F3\\u68B3\\u7406\\u548C\\u5C55\\u671B\\u4E00\\u4E0B\\u672A\\u6765\\u7684\\u53D1\\u5C55\\u8D8B\\u52BF\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:20,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:22,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"Half a year ago, people were still teasing how distorted the hands of characters in AI drawings were. However, today, we can see some images that are comparable to photography. Perhaps one of the differences is that: AI image is too smooth and perfect.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:24,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u534A\\u5E74\\u524D\\uFF0C\\u4EBA\\u4EEC\\u8FD8\\u5728\\u8C03\\u4F83 AI \\u753B\\u7684\\u4EBA\\u7269\\u624B\\u6709\\u591A\\u626D\\u66F2\\u3002 \\u7136\\u800C\\u4ECA\\u5929\\uFF0C\\u6211\\u4EEC\\u53EF\\u4EE5\\u770B\\u5230\\u4E00\\u4E9B\\u582A\\u6BD4\\u6444\\u5F71\\u7684\\u56FE\\u50CF, \\u4E5F\\u8BB8\\u5DEE\\u5F02\\u4E4B\\u4E00\\u662F\\uFF1AAI \\u56FE\\u50CF\\u8FC7\\u4E8E\\u6D41\\u7545\\u548C\\u5B8C\\u7F8E\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:26,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:28,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.h3,{id:\"in-terms-of-images-\\u56FE\\u50CF\\u5904\\u7406\\u65B9\\u9762\",children:[(0,r.jsxDEV)(t.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#in-terms-of-images-\\u56FE\\u50CF\\u5904\\u7406\\u65B9\\u9762\",children:(0,r.jsxDEV)(t.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this)},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this),\"In terms of images (\\u56FE\\u50CF\\u5904\\u7406\\u65B9\\u9762)\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:30,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:[\"It is now possible to embed text into natural images \",(0,r.jsxDEV)(t.a,{href:\"https://x.com/daniel_eckler/status/1705202342159884742?s=20\",children:\"here\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:32,columnNumber:54},this),\" and \",(0,r.jsxDEV)(t.a,{href:\"https://x.com/fabianstelzer/status/1704146823877730683?s=20\",children:\"there\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:32,columnNumber:126},this),\" , which is perfect for posters or advertisement. This may takes a long time for human designers to design and create. We can even make some short animations to make the pictures move (\",(0,r.jsxDEV)(t.a,{href:\"https://x.com/DiffusionPics/status/1706391310561841206?s=20\",children:\"check here\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:32,columnNumber:379},this),\" and \",(0,r.jsxDEV)(t.a,{href:\"https://x.com/mhgenerate/status/1704271148328841405?s=20\",children:\"here\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:32,columnNumber:457},this),\"). Such an achievement is not difficult to expect before: a video is made of pictures frame by frame. Now AI can generate pictures, how far are we from videos and animations?\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:32,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:[\"\\u73B0\\u5728\\u6211\\u4EEC\\u53EF\\u4EE5\\u5C06\\u6587\\u672C\\u5D4C\\u5165\\u5230\\u81EA\\u7136\\u56FE\\u50CF\\u4E2D(\",(0,r.jsxDEV)(t.a,{href:\"https://x.com/daniel_eckler/status/1705202342159884742?s=20\",children:\"\\u6B64\\u5904\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:34,columnNumber:19},this),\"\\u548C\",(0,r.jsxDEV)(t.a,{href:\"https://x.com/fabianstelzer/status/1704146823877730683?s=20\",children:\"\\u6B64\\u5904\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:34,columnNumber:85},this),\")\\uFF0C\\u975E\\u5E38\\u9002\\u5408\\u6D77\\u62A5\\u6216\\u5E7F\\u544A\\u3002 \\u8FD9\\u53EF\\u80FD\\u9700\\u8981\\u4EBA\\u7C7B\\u8BBE\\u8BA1\\u5E08\\u82B1\\u8D39\\u5F88\\u957F\\u7684\\u65F6\\u95F4\\u6765\\u8BBE\\u8BA1\\u548C\\u521B\\u9020\\u3002\\u6211\\u4EEC\\u751A\\u81F3\\u53EF\\u4EE5\\u5236\\u4F5C\\u4E00\\u4E9B\\u7B80\\u77ED\\u7684\\u52A8\\u753B(\\u67E5\\u770B\",(0,r.jsxDEV)(t.a,{href:\"https://x.com/DiffusionPics/status/1706391310561841206?s=20\",children:\"\\u6B64\\u5904\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:34,columnNumber:205},this),\"\\u548C\",(0,r.jsxDEV)(t.a,{href:\"https://x.com/mhgenerate/status/1704271148328841405?s=20\",children:\"\\u6B64\\u5904\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:34,columnNumber:271},this),\")\\u3002\\u8FD9\\u6837\\u7684\\u6210\\u5C31\\u5E76\\u4E0D\\u96BE\\u9884\\u6599\\u5230\\uFF1A\\u89C6\\u9891\\u662F\\u7531\\u4E00\\u5E27\\u4E00\\u5E27\\u7684\\u56FE\\u7247\\u7EC4\\u6210\\u7684\\u3002\\u73B0\\u5728 AI \\u53EF\\u4EE5\\u751F\\u6210\\u56FE\\u7247\\u4E86\\uFF0C\\u6211\\u4EEC\\u79BB\\u89C6\\u9891\\u3001\\u52A8\\u753B\\u8FD8\\u6709\\u591A\\u8FDC\\uFF1F\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:34,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:36,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.h3,{id:\"in-terms-of-speech-\\u8BED\\u97F3\\u65B9\\u9762\",children:[(0,r.jsxDEV)(t.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#in-terms-of-speech-\\u8BED\\u97F3\\u65B9\\u9762\",children:(0,r.jsxDEV)(t.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this)},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this),\"In terms of speech (\\u8BED\\u97F3\\u65B9\\u9762)\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:38,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"today we can already see that AI can imitate a person's tone of voice. In terms of computer vision, we can now easily make a person's mouth make various mouth shapes. So with the combination of these technologies, not surprisingly, we have such a tool: a person speaks in a video in English, and then through AI, the content of his speech, the characteristics of his voice, and even the shape of his mouth have become speaking another language. Of course, if we want to truly understand and integrate into a place and culture, we will still learn the language, but imagine how much less inconvenient this will be for a monolingual person.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:40,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u4ECA\\u5929\\u6211\\u4EEC\\u5DF2\\u7ECF\\u53EF\\u4EE5\\u770B\\u5230\\u4EBA\\u5DE5\\u667A\\u80FD\\u53EF\\u4EE5\\u6A21\\u4EFF\\u4EBA\\u7684\\u8BED\\u6C14\\u3002\\u5728\\u8BA1\\u7B97\\u673A\\u89C6\\u89C9\\u65B9\\u9762\\uFF0C\\u6211\\u4EEC\\u73B0\\u5728\\u53EF\\u4EE5\\u8F7B\\u677E\\u5730\\u8BA9\\u4E00\\u4E2A\\u4EBA\\u7684\\u5634\\u5DF4\\u505A\\u51FA\\u5404\\u79CD\\u5634\\u578B\\u3002\\u90A3\\u4E48\\u6709\\u4E86\\u8FD9\\u4E9B\\u6280\\u672F\\u7684\\u7ED3\\u5408\\uFF0C\\u4E0D\\u51FA\\u610F\\u5916\\uFF0C\\u6211\\u4EEC\\u5C31\\u6709\\u4E86\\u8FD9\\u6837\\u4E00\\u4E2A\\u5DE5\\u5177\\uFF1A\\u4E00\\u4E2A\\u4EBA\\u7528\\u82F1\\u8BED\\u5728\\u89C6\\u9891\\u4E2D\\u8BF4\\u8BDD\\uFF0C\\u7136\\u540E\\u901A\\u8FC7 AI\\uFF0C\\u5F97\\u5230\\u4ED6\\u8BF4\\u8BDD\\u7684\\u5185\\u5BB9\\uFF0C\\u4ED6\\u58F0\\u97F3\\u7684\\u7279\\u5F81\\uFF0C\\u751A\\u81F3\\u4ED6\\u5634\\u7684\\u5F62\\u72B6 \\u5DF2\\u7ECF\\u53D8\\u6210\\u8BF4\\u53E6\\u4E00\\u79CD\\u8BED\\u8A00\\u4E86\\u3002 \\u5F53\\u7136\\uFF0C\\u5982\\u679C\\u6211\\u4EEC\\u60F3\\u771F\\u6B63\\u7406\\u89E3\\u5E76\\u878D\\u5165\\u4E00\\u4E2A\\u5730\\u65B9\\u548C\\u6587\\u5316\\uFF0C\\u6211\\u4EEC\\u4ECD\\u7136\\u4F1A\\u5B66\\u4E60\\u8BED\\u8A00\\uFF0C\\u4F46\\u60F3\\u8C61\\u4E00\\u4E0B\\u8FD9\\u5BF9\\u4E8E\\u53EA\\u4F1A\\u4E00\\u79CD\\u8BED\\u8A00\\u7684\\u4EBA\\u6765\\u8BF4\\u4F1A\\u51CF\\u5C11\\u591A\\u5C11\\u4E0D\\u4FBF\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:42,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:44,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.h3,{id:\"in-terms-of-hardware-\\u786C\\u4EF6\\u65B9\\u9762\",children:[(0,r.jsxDEV)(t.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#in-terms-of-hardware-\\u786C\\u4EF6\\u65B9\\u9762\",children:(0,r.jsxDEV)(t.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this)},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this),\"In terms of hardware (\\u786C\\u4EF6\\u65B9\\u9762)\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:46,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"we have seen IT giants entering space computing and the metaverse. Yesterday I saw Meta Glasses, which can help us immediately determine how long it takes the barbecue to finish, whether there is any foul play during sports, and landmarks information. Relevantly, chatGPT\\u2019s latest image input feature can guide us on how to repair bicycles. Think about what this will look like if it is placed on glasses.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:48,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u6211\\u4EEC\\u5DF2\\u7ECF\\u770B\\u5230 IT \\u5DE8\\u5934\\u8FDB\\u5165\\u7A7A\\u95F4\\u8BA1\\u7B97\\u548C\\u5143\\u5B87\\u5B99\\u7684\\u5E03\\u5C40\\u3002\\u6628\\u5929\\u6211\\u770B\\u5230\\u4E86 Meta Glasses\\uFF0C\\u5B83\\u53EF\\u4EE5\\u5E2E\\u52A9\\u6211\\u4EEC\\u7ACB\\u5373\\u5224\\u65AD\\u9762\\u524D\\u7684\\u70E4\\u8089\\u8981\\u70E4\\u591A\\u4E45\\uFF0C\\u8FD0\\u52A8\\u8FC7\\u7A0B\\u4E2D\\u662F\\u5426\\u6709\\u72AF\\u89C4\\u884C\\u4E3A\\uFF0C\\u4EE5\\u53CA\\u5730\\u6807\\u4FE1\\u606F\\u3002 \\u4E0E\\u6B64\\u76F8\\u5173\\u7684\\u662F\\uFF0CchatGPT \\u6700\\u65B0\\u7684\\u56FE\\u50CF\\u8F93\\u5165\\u529F\\u80FD\\u53EF\\u4EE5\\u6307\\u5BFC\\u6211\\u4EEC\\u5982\\u4F55\\u4FEE\\u7406\\u81EA\\u884C\\u8F66\\u3002 \\u60F3\\u8C61\\u4E00\\u4E0B\\u5982\\u679C\\u628A\\u5B83\\u6234\\u5728\\u773C\\u955C\\u4E0A\\u4F1A\\u662F\\u4EC0\\u4E48\\u6837\\u5B50\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:50,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:52,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.h3,{id:\"so-we-can-imagine-a-future-like-this-\\u672A\\u6765\\u5C55\\u671B-\",children:[(0,r.jsxDEV)(t.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#so-we-can-imagine-a-future-like-this-\\u672A\\u6765\\u5C55\\u671B-\",children:(0,r.jsxDEV)(t.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this)},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this),\"So we can imagine a future like this (\\u672A\\u6765\\u5C55\\u671B) :\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:54,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.ol,{children:[`\n`,(0,r.jsxDEV)(t.li,{children:\"In the future, everyone can make short movies and animations. It is as easy as writing a blog or post. You can choose the characters (even yourself) and their voice characteristics. (A 2-hour movie or TV series may be as difficult as writing a book, but of course it\\u2019s difficult from another perspective). No wonder Hollywood wants to obtain the rights to use the actors\\u2019 AI portraits, haha.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:56,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:56,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u672A\\u6765\\u4EBA\\u4EBA\\u90FD\\u53EF\\u4EE5\\u5236\\u4F5C\\u77ED\\u7247\\u3001\\u52A8\\u753B\\uFF0C\\u5C31\\u50CF\\u5199\\u535A\\u5BA2\\u6216\\u5E16\\u5B50\\u4E00\\u6837\\u7B80\\u5355\\u3002\\u4F60\\u53EF\\u4EE5\\u9009\\u62E9\\u89D2\\u8272\\uFF08\\u751A\\u81F3\\u60A8\\u81EA\\u5DF1\\uFF09\\u53CA\\u5176\\u58F0\\u97F3\\u7279\\u5F81\\u3002\\uFF08\\u4E00\\u90E8 2 \\u5C0F\\u65F6\\u7684\\u7535\\u5F71\\u6216\\u7535\\u89C6\\u5267\\u53EF\\u80FD\\u548C\\u5199\\u4E00\\u672C\\u4E66\\u4E00\\u6837\\u56F0\\u96BE\\uFF0C\\u4F46\\u662F\\u8FD9\\u662F\\u53E6\\u4E00\\u4E2A\\u89D2\\u5EA6\\u7684\\u56F0\\u96BE\\uFF09\\u3002\\u96BE\\u602A\\u597D\\u83B1\\u575E\\u8981\\u83B7\\u5F97\\u6F14\\u5458 AI \\u8096\\u50CF\\u7684\\u4F7F\\u7528\\u6743\\uFF0C\\u54C8\\u54C8\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:58,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:60,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.ol,{start:\"2\",children:[`\n`,(0,r.jsxDEV)(t.li,{children:\"Everyone has a customized Jarvis. It is no longer sci-fi. Put it in glasses, it can teach you how to draw on the white paper in front of you and display the music sheet in front of your face when you play instrument, telling you what to play next when you practice the piano, or teaching you how to cook step by step.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:62,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:62,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u6BCF\\u4E2A\\u4EBA\\u90FD\\u6709\\u4E00\\u4E2A\\u5B9A\\u5236\\u7684\\u8D3E\\u7EF4\\u65AF\\u3002\\u8FD9\\u4E0D\\u518D\\u662F\\u79D1\\u5E7B\\u5C0F\\u8BF4\\u3002\\u628A\\u5B83\\u653E\\u5728\\u773C\\u955C\\u91CC\\uFF0C\\u5B83\\u53EF\\u4EE5\\u6559\\u4F60\\u5982\\u4F55\\u5728\\u4F60\\u9762\\u524D\\u7684\\u767D\\u7EB8\\u4E0A\\u753B\\u753B\\uFF0C\\u5E76\\u5728\\u4F60\\u6F14\\u594F\\u4E50\\u5668\\u65F6\\u5C06\\u4E50\\u8C31\\u663E\\u793A\\u5728\\u4F60\\u9762\\u524D\\uFF0C\\u5728\\u4F60\\u7EC3\\u4E60\\u94A2\\u7434\\u65F6\\u544A\\u8BC9\\u4F60\\u63A5\\u4E0B\\u6765\\u8981\\u6F14\\u594F\\u4EC0\\u4E48\\uFF0C\\u6216\\u8005\\u6559\\u4F60\\u5982\\u4F55\\u4E00\\u6B65\\u4E00\\u6B65\\u505A\\u996D\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:64,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:66,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.ol,{start:\"3\",children:[`\n`,(0,r.jsxDEV)(t.li,{children:\"No customer service. Although I still hate the AI's voice and stupidity when I'm on the phone now, I've been asking chatGPT a lot of things. If product descriptions and so on are used for training by large models in the future, then we can solve any product usage problems locally through glasses or mobile phones.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:68,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:68,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u6CA1\\u6709\\u5BA2\\u670D\\u3002\\u867D\\u7136\\u6211\\u73B0\\u5728\\u6253\\u7535\\u8BDD\\u65F6\\u4ECD\\u7136\\u8BA8\\u538C AI \\u7684\\u58F0\\u97F3\\u548C\\u611A\\u8822\\uFF0C\\u4F46\\u6211\\u5DF2\\u7ECF\\u5411 chatGPT \\u8BE2\\u95EE\\u4E86\\u5F88\\u591A\\u4E8B\\u60C5\\u3002\\u5982\\u679C\\u672A\\u6765\\u5927\\u6A21\\u578B\\u4F7F\\u7528\\u4EA7\\u54C1\\u4F7F\\u7528\\u8BF4\\u660E\\u7B49\\u8FDB\\u884C\\u8BAD\\u7EC3\\uFF0C\\u90A3\\u4E48\\u6211\\u4EEC\\u53EF\\u4EE5\\u901A\\u8FC7\\u773C\\u955C\\u6216\\u624B\\u673A\\u5728\\u672C\\u5730\\u89E3\\u51B3\\u4EFB\\u4F55\\u4EA7\\u54C1\\u4F7F\\u7528\\u95EE\\u9898\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:70,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:72,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.ol,{start:\"4\",children:[`\n`,(0,r.jsxDEV)(t.li,{children:[\"Other scenarios. You don\\u2019t want to read several pages of a contract word for word, so you take a picture of it and give it to the AI (distrustful though), and it can help you figure out where there are hidden things agains you or unreasonable aspects. Or you are parking on the side of the road, and the complicated instructions make you confused, but \",(0,r.jsxDEV)(t.a,{href:\"https://x.com/petergyang/status/1707169696049668472?s=20\",children:\"AI can directly tell you whether you can park and how long you can park.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:74,columnNumber:356},this)]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:74,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:74,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:[\"\\u5176\\u4ED6\\u573A\\u666F\\u3002\\u4F60\\u4E0D\\u60F3\\u9010\\u5B57\\u9010\\u53E5\\u5730\\u9605\\u8BFB\\u51E0\\u9875\\u5408\\u540C\\uFF0C\\u6240\\u4EE5\\u4F60\\u628A\\u5B83\\u62CD\\u4E0B\\u6765\\u4EA4\\u7ED9\\u4EBA\\u5DE5\\u667A\\u80FD\\uFF08\\u5C3D\\u7BA1\\u5B58\\u5728\\u4E0D\\u4FE1\\u4EFB\\u95EE\\u9898\\uFF09\\uFF0C\\u5B83\\u53EF\\u4EE5\\u5E2E\\u52A9\\u4F60\\u627E\\u51FA\\u54EA\\u91CC\\u6709\\u5BF9\\u4F60\\u4E0D\\u5229\\u6216\\u4E0D\\u5408\\u7406\\u7684\\u5730\\u65B9\\u3002\\u6216\\u8005\\u4F60\\u5728\\u8DEF\\u8FB9\\u505C\\u8F66\\uFF0C\\u590D\\u6742\\u7684\\u6307\\u4EE4\\u8BA9\\u4F60\\u4E00\\u5934\\u96FE\\u6C34\\uFF0C\\u4F46\",(0,r.jsxDEV)(t.a,{href:\"https://x.com/petergang/status/1707169696049668472?s=20\",children:\"AI \\u53EF\\u4EE5\\u76F4\\u63A5\\u544A\\u8BC9\\u4F60\\u662F\\u5426\\u53EF\\u4EE5\\u505C\\u8F66\\u4EE5\\u53CA\\u53EF\\u4EE5\\u505C\\u8F66\\u591A\\u957F\\u65F6\\u95F4\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:76,columnNumber:92},this)]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:76,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:78,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"The current large models are based on the huge amount of data training, and winning by quantity is never the optimal solution. That\\u2019s why Sam Altman said,\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:80,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u76EE\\u524D\\u7684\\u5927\\u578B\\u6A21\\u578B\\u90FD\\u662F\\u57FA\\u4E8E\\u6D77\\u91CF\\u6570\\u636E\\u8BAD\\u7EC3\\uFF0C\\u800C\\u4EE5\\u91CF\\u53D6\\u80DC\\u4ECE\\u6765\\u90FD\\u4E0D\\u662F\\u6700\\u4F18\\u65B9\\u6848\\u3002\\u8FD9\\u5C31\\u662F\\u4E3A\\u4EC0\\u4E48 Sam Altman \\u8BF4\\uFF0C\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:82,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.blockquote,{children:[`\n`,(0,r.jsxDEV)(t.p,{children:\"we\\u2019re at the end of the era where it\\u2019s gonna be these giant models, and we\\u2019ll make them better in other ways.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:84,columnNumber:3},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:84,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.blockquote,{children:[`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u6211\\u4EEC\\u6B63\\u5904\\u4E8E\\u8FD9\\u4E9B\\u5DE8\\u578B\\u6A21\\u578B\\u65F6\\u4EE3\\u7684\\u672B\\u671F\\uFF0C\\u6211\\u4EEC\\u5C06\\u901A\\u8FC7\\u5176\\u4ED6\\u65B9\\u5F0F\\u8BA9\\u5B83\\u4EEC\\u53D8\\u5F97\\u66F4\\u597D\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:86,columnNumber:3},this),`\n`]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:86,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.hr,{},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:88,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.h3,{id:\"ending-\\u7ED3\\u8BED\",children:[(0,r.jsxDEV)(t.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#ending-\\u7ED3\\u8BED\",children:(0,r.jsxDEV)(t.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this)},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this),\"Ending (\\u7ED3\\u8BED)\"]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:90,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"I really want to pick up the knowledge of machine learning and deep learning again when I have free time, and keep up with the current trends, but I always feel that I am unable to do so. Because whether it is papers or products, they are developing too fast.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:92,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u6211\\u5F88\\u60F3\\u6709\\u7A7A\\u7684\\u65F6\\u5019\\u91CD\\u65B0\\u62FE\\u8D77\\u673A\\u5668\\u5B66\\u4E60\\u548C\\u6DF1\\u5EA6\\u5B66\\u4E60\\u7684\\u77E5\\u8BC6\\uFF0C\\u8DDF\\u4E0A\\u5F53\\u524D\\u7684\\u6F6E\\u6D41\\uFF0C\\u4F46\\u603B\\u89C9\\u5F97\\u529B\\u4E0D\\u4ECE\\u5FC3\\u3002 \\u56E0\\u4E3A\\u65E0\\u8BBA\\u662F\\u8BBA\\u6587\\u8FD8\\u662F\\u4EA7\\u54C1\\uFF0C\\u5B83\\u4EEC\\u53D1\\u5C55\\u5F97\\u592A\\u5FEB\\u4E86\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:94,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"The picture at the beginning is of a steam engine. Now that steam engines are available, would the industrial revolution be far in the future? We truly live in an age of wonder.\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:96,columnNumber:1},this),`\n`,(0,r.jsxDEV)(t.p,{children:\"\\u5F00\\u5934\\u7684\\u56FE\\u7247\\u662F\\u84B8\\u6C7D\\u673A\\u3002\\u65E2\\u7136\\u84B8\\u6C7D\\u673A\\u5DF2\\u7ECF\\u95EE\\u4E16\\uFF0C\\u5DE5\\u4E1A\\u9769\\u547D\\u8FD8\\u4F1A\\u9065\\u8FDC\\u5417\\uFF1F\\u6211\\u4EEC\\u786E\\u5B9E\\u751F\\u6D3B\\u5728\\u4E00\\u4E2A\\u5145\\u6EE1\\u795E\\u5947\\u7684\\u65F6\\u4EE3\\u3002\"},void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:98,columnNumber:1},this)]},void 0,!0,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\",lineNumber:1,columnNumber:1},this)}function _t(u={}){let{wrapper:t}=u.components||{};return t?(0,r.jsxDEV)(t,Object.assign({},u,{children:(0,r.jsxDEV)(ke,u,void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this)}),void 0,!1,{fileName:\"/Users/ethan/Documents/GitHub/portfolio-website-master/content/blog/_mdx_bundler_entry_point-bdc31e95-dd09-41ce-b2c3-c088c0bdce94.mdx\"},this):ke(u)}var gt=_t;return ht(yt);})();\n/*! Bundled license information:\n\nreact/cjs/react-jsx-dev-runtime.development.js:\n  (**\n   * @license React\n   * react-jsx-dev-runtime.development.js\n   *\n   * Copyright (c) Facebook, Inc. and its affiliates.\n   *\n   * This source code is licensed under the MIT license found in the\n   * LICENSE file in the root directory of this source tree.\n   *)\n*/\n;return Component;"
  },
  "_id": "blog/things-are-changing-very-fast.mdx",
  "_raw": {
    "sourceFilePath": "blog/things-are-changing-very-fast.mdx",
    "sourceFileName": "things-are-changing-very-fast.mdx",
    "sourceFileDir": "blog",
    "contentType": "mdx",
    "flattenedPath": "blog/things-are-changing-very-fast"
  },
  "type": "Post",
  "slug": "/blog/things-are-changing-very-fast",
  "slugAsParams": "things-are-changing-very-fast"
}